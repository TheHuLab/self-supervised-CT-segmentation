\section{Experiments}


\subsection{Datasets}
The dataset that we use is an integrative resource of chest computed tomography images and clinical features of patients with COVID-19 pneumonia (ICTCF) \cite{ref12} which contains the severity score for each CT lung image and CT lung images from medical segmentation website \cite{ref13}. 

ICTCF contains 127 types of clinical features and laboratory-confirmed cases of COVID-19 from 1170 patients including the severity of the CT lung images. However, the ICTCF dataset does not contain the segmentation labels for the ground-glass opacities and the consolidation in the CT lung images. In total, there are 6654 of CT lung images in ICTCF dataset. Originally, there were 1521 patients. However, some of the patients are missing CT lung images. We remove these patients that are missing CT lung images. After preprocessing the patients, the dataset was left with 1338 patients that contain CT lung images. The dataset can be found here: http://ictcf.biocuckoo.cn/.  We use these ICTCF CT lung images without the ground truth segmentation labels in combination with the MedSeg dataset to undergo self-supervised learning to predict image in-painting. 

As for the MedSeg dataset, they contain ground truth labels for the segmentation for ground-glass opacities and consolidation of the CT lung images. The total amount of CT lung images contain in MedSeg dataset is 932 CT lung images. We randomly assign the CT lung images into a training set, validation set, and testing set of which the training set contains 698 CT lung images, the validation set contains 114 CT lung images, and the testing set contains 117 CT lung images. 

The assignment of the dataset can be seen in Table \ref{tab:dataset}.

\begin{table}[!h]
	\centering
	\begin{tabular}{|c||c|c|c|c|} \hline
		Data split & Source & Segmented & Images & Patients \\\hline
		Training & \vtop{\hbox{\strut Med-Seg}\hbox{\strut ICTCF}}&
		\vtop{\hbox{\strut Yes}\hbox{\strut No}} & 
		\vtop{\hbox{\strut 698}\hbox{\strut 6654}}&
		\vtop{\hbox{\strut 39}\hbox{\strut 1338}}\\\hline
		Validation & Med-Seg & Yes & 114 & 35 \\\hline
		Testing & Med-Seg & Yes & 117 & 35 \\\hline
	\end{tabular}
	\caption{This table shows the data distribution between the datasets that we use to evaluate our model on. Med-Seg refers to the COVID-19 CT Segmentation data set and ICTCF refers to the ICTCF data set.}
	\label{tab:dataset}
\end{table}


\subsection{Experimental Settings}
During the self-supervised image inpainting stage, we train the network for 2000 epochs. The network is trained for the first 200 epochs before we train the coach network for 200 epochs which increases the complexity of the masks generated. After that, we alternate in between training the self-supervised image inpainting and the coach network with 100 epochs in between. For every alternating between the training of the self-supervised image inpainting and the coach network, we set the learning rate to 0.1 at the start of the epoch, we set the learning rate to 0.01 at 40th epoch, we set the learning rate to 0.001 at 80th epochs, and 0.0001 at the 90th epoch.  We use SGD as the optimizer for the self-supervised image inpainting.  We set the momentum to 0.9 and the weight decay to 0.0005. As for the optimizer for the coach network, we use Adam optimizer with a learning rate of 0.00001.

For the Single InfNet, we train the network for 500 epochs. We use Adam as the optimizer with a learning rate of 0.0001. 

For the Multi InfNet, we train the network for 500 epochs. We use SGD as the optimizer. The momentum is set as 0.7 and the learning rate is set as 0.01.

As for the Multi InfNet with added focal loss and lookahead optimizer, we trained the network for 500 epochs, we use lookahead optimizer with k=5 and alpha=0.5 and warp the lookahead optimizer around SGD optimizer where the momentum is set as 0.7 and the learning rate is set as 0.01.

For the self-supervised version for both Single InfNet and Multi InfNet, the self-supervised image in-painting is first trained. Then the weights from the trained networks except for the last layer are transferred to be used to train on the segmentation of the CT lung images.

We compare our method against the supervised %and semi-supervised \cite{ref13,ref14} 
\cite {ref14} models trained on COVID-19 dataset. We train and follow using the same network structure but change from supervised learning to self-supervised learning and compare the performance between supervised and self-supervised.

We use this approach to determine if self-supervised learning can be a useful task to help InfNet improve its performance in segmenting the ground-glass opacities or consolidation around the infected region of the CT lung images.

\subsection{Performance Evaluation Metrics}
we will show the results of our experiments obtained. We show the comparison of the results between the supervised and the self-supervised version of the InfNet.

%The result for our comparison between the baseline InfNet model and our self-supervised model can be seen in Table \ref{tab:single}, and Table \ref{tab:multi-weakprior}. 
The table is plotted with several metrics: F1, IoU, Recall, and Precision. 

The F1-Score is also called the Dice Coefficient, it is used to measure the overlap between the ground-truth infected region and the predicted infected region. The F1-Score equation is defined as:

\begin{equation}
F1 = \frac{2 * | T \cap P |}{|T| + |P|}
\end{equation}

where T is the ground truth infected region and P is the predicted infected region.

The IoU is a different method to measure the overlap between the ground truth infected region and the predicted infected region. The IoU equation is defined as:

\begin{equation}
IoU = \frac{T \cup P}{T \cap P}
\end{equation}

where T is the ground truth infected region and P is the predicted infected region.

The Recall is used to measure the how much of the ground truth infected region is present in the predicted infected region. The equation is as follow:

\begin{equation}
Recall = \frac{T \cap P}{T}
\end{equation}

where T is the ground truth infected region and P is the predicted infected region.

The Precision is used to measure how much of the predicted infected region is present in the ground truth infected region. The equation is as follow:

\begin{equation}
Precision = \frac{T \cap P}{P}
\end{equation}

where T is the ground truth infected region and P is the predicted infected region.

There are cases when the calculated F1, IoU, Recall, or Precision will contain NaN value due to the fact that the denominator is 0. We will ignore NaN values into our calculation and continue the calculation for other metrics.

For the table that contains mean and error, the mean are calculated as:
\begin{equation}
mean =  \frac{\sum_{i=1}^{N}Metric(\hat{y_i}, y_i)}{N}
\end{equation}
Where Metric refers to either \textit{F1, IoU, Recall, Precision.} N refers to the number of test data samples.
The error is:
\begin{equation}
error =  SE \times 1.96
\end{equation}
where SE is the standard error of the test data samples for the metric multiplied by 1.96.
Note that Mean $\pm$Error is the 95\% confidence interval.