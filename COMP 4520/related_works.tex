\section{Related works}

Several works have been proposed to create image segmentation for CT scan lung images of COVID-19 positive patients. They have demonstrated effective solutions using deep neural networks to accurately predict if a patient has COVID-19 positive or negative. 

A study has been conducted that uses supervised learning to train multiple models for different tasks where the study uses both classification and image segmentation tasks for COVID-19 detection through multi-tasks learning. The study uses Inception Residual Recurrent Neural Network (IRRCNN) for the classification of COVID-19 detection and uses Nabla-Net (NABLA-N) network for infected region segmentation for X-ray and CT images scan \cite{ref3}. Transfer learning is used to retrain the IRRCNN model with samples to differentiate between COVID-19 positive samples and negative samples in the classification phase. Mathematical Morphological approaches are implemented for selecting appropriate contours for chest region selection in the segmentation phase with NABLA-N network. Some classical imaging and adaptive threshold approaches are applied to extract the features to identify infected regions of COVID-19. They used a total number of 5,216 samples of which 3,875 samples are pneumonia and 1,341 samples are normal.

Another study \cite{ref4} introduces a supervised learning feature variation block and progressive atrious spatial pyramid pooling block using COVID-segNet, a high accuracy network that can create a segmentation of COVID-19 infection from chest CT images. The network consists of an Encoder and a Decoder with residual skip connection connecting the encoder and the decoder at their respective layer, following the architecture of UNET \cite{ref5}. Their main findings include the introduction of an FV block and a PASPP block. FV block consists of three branches - contrast enhancement branch, position sensitive branch, and identity branch. These branches can enable automatic change of parameters to display positions and boundaries of COVID-19. The PASPP block takes features extracted from the FV block to acquire semantic information with a variety of receptive fields. The dataset that they used consists of 21,658 labeled chest CT images, of which 861 CT images are confirmed COVID-19. 

The paper above however uses supervised learning and conducted the study with a good amount of data samples to train the network to achieve high performance. They obtained their dataset from hospitals through obtaining permission. We would like to create a network that does not require a much-labeled dataset to be able to achieve good performance. By doing this method, we could bring this network forward to detect new lung diseases when there is not many datasets available. Besides that, the paper is only able to recognize the presence of COVID-19 in a patient, but the papers could not quantify the severity of the disease. 

While there is a limited number of public data samples available for CT COVID-19 lung image segmentation, it will not be feasible to train a network to achieve high performance. As there are not many COVID CT dataset that contains the segmentation ground-truth, we train a network that contains the segmentation of the infected region so that the prediction results from our model are more intuitive and easily comprehensible. Several kinds of research that resolve this issue. One method is to use semi-supervised learning to mitigate the problem of having a low number of data samples to improve the performance of deep neural networks. Instead of having to manually annotate the data, semi-supervised learning utilizes the unlabeled data samples to aid in the training for the network.

Fan et al. \cite{ref2} used semi-supervised learning to enlarge the limited number of training samples for CT lung image segmentation. They developed a model called InfNet and semi-InfNet. The InfNet version of the model uses a fully supervised method to predict the segmentation of the CT images for ground-glass opacities and consolidations. The model outputs 4 images of the segmentation for the CT lung images that contain either ground-glass opacities or consolidations with different image sizes. The segmentation of the different image sizes is resized to the same size as the ground truth of the segmentation to compute the loss function. They also use an edge loss to guide the model to predict the boundary area of the segmentation. To improve InfNet, they use semi-supervised by progressively enlarging the training dataset with unlabeled data using a random sampling strategy. Specifically, they generate pseudo labels for unlabeled CT lung images. The advantage of using semi-supervised learning is that we can generate pseudo labels to increase the number of data samples. However, semi-supervised learning still requires to generate new examples through the use of unlabeled CT lung images before being able to undergo its learning procedure. This requires the use of unlabeled CT lung images to generate weakly labeled samples that are treated normally as labeled CT lung images to be fed into the network to train. This would be more time consuming as the network would have to first be trained on the labeled CT lung images, then evaluate the trained network on the unlabeled CT lung images to convert the unlabeled CT lung images into labeled CT lung images. After which the whole labeled CT lung images would be retrained again. This would take more than 3 times the time to train a supervised version of the network.

Another study \cite{ref6} uses Task-Based Feature Extraction Network (TFEN) and Covid-19 Identification Network (CIN).  They propose to use a task-specific feature extraction network that is tailored to CT lung images with three different classes: Healthy, pneumonia, and COVID-19 cases. They also mentioned that the dataset for COVID-19 is still limited and there is not enough high-quality dataset. They treat the task-specific feature extraction network as autoencoders and train the overall TFEN module to extract the relevant features from the CT images. Then, they use CIN to perform classification on the extracted features from the TFEN module. They can easily detect the abnormal regions and differentiate between them very accurately by making use of prior information even when a person contains limited CT images. This helped them develop a semi-supervised feature extraction network that allows obtaining the relevant prior information to perform the classification to mimic human behaviors. However, this study does not undergo segmentation of the CT lung images for better diagnosis of the CT lung images.

There is a study that predicts the severity score of COVID-19 on chest x-ray with deep learning \cite{ref7}. They use a DenseNet model from the TorchXRayVision library as DenseNet models have been shown to predict Pneumonia well. They use a pre-training step to train the feature extraction layers and a task prediction layer. The pre-training step was used to generate general representations of lungs and other Chest X-rays (CXRs) that they would have unable to achieve from the small set of COVID-19 images available. They use a network that outputs 18 outputs of a representation of the image, 4 outputs that are a hand-picked subset which contains the radiological findings (pneumonia, consolidation, lung opacity, and infiltration), and a lung opacity output. This study however did not use evaluate the segmentation of the infected region. They were only able to classify the CT lung images.

Lin et al. \cite{ref8} noticed that class imbalance encountered during the training of dense detectors tend to overwhelm the cross entropy loss function. The negative samples that are easily classified comprise the majority of the loss and have a huge influence on the gradient. Instead, they propose a loss function, focal loss, to reduce the weight of easy examples and focus more on hard negatives. Focal loss was able to improve the performance of the dense detector when the dataset trained on has class imbalance. 

SGD remains a popular optimizer to be used in training deep learning networks. There are improvement to SGD that includes AdaGrad \cite{ref9} or Adam \cite{ref10} which uses adaptive learning to optimize the weights of the deep learning network. However, hyperparameter tuning are costly to ensure the improvement of performance in deep learning networks with adaptive learning. Zhang et al. \cite{ref11} present Lookahead that is less sensitive to suboptimals hyperparameters and reduce the need for additional effort to tune the hyperparameter. Lookahead optimizer warps around SGD or Adam and is able to achieve fast convergence across multiple deep learning tasks with minimal computational overhead.

%Another study \cite{ref9} uses fine-grained segmentation networks (FGSN) to produce a dense segmentation map. Instead of using manually annotated labels, they created labels in a self-supervised manner. Features were extracted in certain layers in the network and clustered using k-means clustering. The cluster assignments are then used as supervision for the training. They showed that the learned representations can contain useful information for visual localization. The performance of the model improved by as much as 15% when trained with self-supervised learning instead of just classification.
